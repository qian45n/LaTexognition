{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ViT\n",
      "  0%|                                                  | 0/1185 [00:00<?, ?it/s]torch.Size([64, 157])\n",
      "torch.Size([64, 1, 1, 157])\n",
      "k:torch.Size([64, 8, 156, 64]), v:torch.Size([64, 8, 156, 64])\n",
      "  0%|                                                  | 0/1185 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qsun/miniconda3/envs/latexocr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/qsun/miniconda3/envs/latexocr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/qsun/project/LaTexognition/pix2tex/train.py\", line 102, in <module>\n",
      "    train(args)\n",
      "  File \"/home/qsun/project/LaTexognition/pix2tex/train.py\", line 57, in train\n",
      "    loss = model.data_parallel(im[j:j+microbatch].to(device), device_ids=args.gpu_devices, tgt_seq=tgt_seq, mask=tgt_mask)*microbatch/args.batchsize\n",
      "  File \"/home/qsun/project/LaTexognition/pix2tex/models/utils.py\", line 18, in data_parallel\n",
      "    return self(x, **kwargs)\n",
      "  File \"/home/qsun/miniconda3/envs/latexocr/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/qsun/project/LaTexognition/pix2tex/models/utils.py\", line 31, in forward\n",
      "    out = self.decoder(tgt_seq, context=encoded, **kwargs)\n",
      "  File \"/home/qsun/miniconda3/envs/latexocr/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/qsun/project/LaTexognition/x_transformers_local/x_transformers/autoregressive_wrapper.py\", line 141, in forward\n",
      "    logits = self.net(inp, **kwargs)\n",
      "  File \"/home/qsun/miniconda3/envs/latexocr/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/qsun/project/LaTexognition/x_transformers_local/x_transformers/x_transformers.py\", line 1366, in forward\n",
      "    x = self.attn_layers(x, mask = mask, mems = mems, **kwargs)\n",
      "  File \"/home/qsun/miniconda3/envs/latexocr/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/qsun/project/LaTexognition/x_transformers_local/x_transformers/x_transformers.py\", line 1119, in forward\n",
      "    out, inter = block(x, mask = mask, context_mask = self_attn_context_mask, attn_mask = attn_mask, rel_pos = self.rel_pos, rotary_pos_emb = rotary_pos_emb, prev_attn = prev_attn, mem = layer_mem)\n",
      "  File \"/home/qsun/miniconda3/envs/latexocr/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/qsun/project/LaTexognition/x_transformers_local/x_transformers/x_transformers.py\", line 778, in forward\n",
      "    k = k.masked_fill(~kv_mask, kv_mask_value)\n",
      "RuntimeError: The size of tensor a (157) must match the size of tensor b (64) at non-singleton dimension 5\n"
     ]
    }
   ],
   "source": [
    "!python -m pix2tex.train --config ViT.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latexocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
